---
# jupyter:
#   jupytext:
#     text_representation:
#       extension: .qmd
#       format_name: quarto
#       format_version: "1.0"
#       jupytext_version: 1.16.6
#   kernelspec:
#     display_name: IV Dist Dash
#     language: python
#     name: iv_dist_dash
author: Ernest Orlowski
jupyter: python3
---

```{python}
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns

data = pd.read_csv(
    "../scratch/causal-inference-in-python-code/causal-inference-in-python/data/cross_sell_email.csv"
)
data
```

```{python}
sns.set_theme("notebook")
sns.set_palette(palette="pastel")
```

```{python}
data2 = data.copy()
(data2.groupby(["cross_sell_email"]).mean())
# data2
```

```{python}
X = ["gender", "age"]
mu = data.groupby("cross_sell_email")[X].mean()
var = data.groupby("cross_sell_email")[X].var()

norm_diff = (mu - mu.loc["no_email"]) / np.sqrt((var + var.loc["no_email"]) / 2)
norm_diff
```

```{python}
df = pd.read_csv(
    "../scratch/causal-inference-in-python-code/causal-inference-in-python/data/enem_scores.csv"
)
df.sort_values(by="avg_score", ascending=False).head(10)
```

```{python}
data = pd.read_csv(
    "../scratch/causal-inference-in-python-code/causal-inference-in-python/data/cross_sell_email.csv"
)

short_email = data.query("cross_sell_email=='short'")["conversion"]
long_email = data.query("cross_sell_email=='long'")["conversion"]
email = data.query("cross_sell_email!='no_email'")["conversion"]
no_email = data.query("cross_sell_email=='no_email'")["conversion"]

data.groupby("cross_sell_email").size()
```

To get the estimate for the standard deviation, you can apply the following equation:

\begin{equation}
\hat{ùõî} = \sqrt{\frac{1}{N - 1}\Sigma_{i = 0}^{N}(x - \bar{x})^{2}}
\end{equation}

```{python}
def se(y: pd.Series):
    return y.std() / np.sqrt(len(y))


print(f"SE for Long Email: {se(long_email):.3g}")
print(f"SE for Short Email: {se(short_email):.3g}")
```

```{python}
print(f"SE for Long Email: {long_email.sem():3g}")
print(f"SE for Short Email: {short_email.sem():3g}")
```

#### Confidence Intervals:
The standard error of the estimate is a measure of confidence. For the frequentist view of statistics, we would say that our data is nothing more than a manifestation of an underlying data-generating process. This process is abstract and ideal. It is governed by true parameters that are unchanged but also unknown to us. In the context of cross-sell email, if we ran multiple experiments  and calculated the conversion rate for each of them, they would fall around the true underlying conversion rate, even if they werent exactly equal to it.
To better understand this, assume you have the true abstract distribution of conversion for the short cross-sell email. Because conversion is either zero or one, it follows a Bernoulli distribution and lets say that the probability of success in this distribution is 0.08. That is, whenever a customer receives the short email, it has an 8% chance of converting. Next, 10,000 experiments are ran. On each one, a sample of 100 customers is collected, and a short email is sent to abserve the average conversion, yielding a total of 10,000 conversion rates. The 10,000 conversion rates from those experiments will be distributed around th true mean of 0.08.

```{python}
n = 100  # 100 customers
conv_rate = 0.08  # tru conversion rate


def run_experiment():
    return np.random.binomial(1, conv_rate, size=n)


np.random.seed(42)

experiments = [run_experiment().mean() for _ in range(10_000)]
```

```{python}

import matplotlib as mpl
```

```{python}
mpl.use("MacOSX")
```

```{python}
%matplotlib inline
plt.figure(figsize = (10, 4))
# freq, bins, img = sns.histplot(experiments, bins = 20, legend = True)
freq, bins, img = plt.hist(experiments, bins = 20, label = "Experiment Means", color = "0.6")
plt.vlines(conv_rate, ymin = 0, ymax = freq.max(), linestyles = "dashed", label = "True Mean", color = "0.3")
plt.legend()
plt.show()
```

